{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"q5Dqm3xuwZgc"},"outputs":[],"source":["from tensorflow.keras.layers import Input, Conv2D, BatchNormalization, MaxPooling2D, UpSampling2D, concatenate, GlobalAveragePooling2D, Dense\n","from tensorflow.keras import Model\n","from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras import optimizers, activations\n","from tensorflow.keras.callbacks import ModelCheckpoint\n","import matplotlib.pyplot as plt\n","from datetime import datetime\n","\n","# Set the input image size\n","IMAGE_SIZE = (224, 224)\n","\n","\n","# Set the paths to your training and testing/validation data\n","train_path = 'G:/Dataset-20230523T171034Z-001/Dataset/train'\n","test_path = 'G:/Dataset-20230523T171034Z-001/Dataset/test'\n","\n","# Create the VGG16 model\n","base_model = VGG16(weights='imagenet', include_top=False, input_shape=IMAGE_SIZE + (3,))\n","\n","# Freeze the layers in the base model\n","for layer in base_model.layers:\n","    layer.trainable = False\n","\n","# Add the input layer\n","input_layer = Input(shape=IMAGE_SIZE + (3,), name=\"input\")\n","\n","# Obtain the output of the last layer in the base model\n","base_model_output = base_model(input_layer)"]},{"cell_type":"code","source":["# Conv1_1_64\n","x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv1')(input_layer)\n","# Conv1_2_64\n","x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv2')(x)\n","# Block1 output for later concatenation\n","block1_conv2_output = x\n","# Batch Normalization1\n","x = BatchNormalization(name='bn1')(x)\n","# MaxPooling1\n","x = MaxPooling2D((2, 2), strides=(2, 2), name='block1_pool')(x)\n","\n","# Block 2\n","# Conv2_1_128\n","x = Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv1')(x)\n","# Conv2_2_128\n","x = Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv2')(x)\n","# Block2 output for later concatenation\n","block2_conv2_output = x\n","# Batch Normalization2\n","x = BatchNormalization(name='bn2')(x)\n","# MaxPooling2\n","x = MaxPooling2D((2, 2), strides=(2, 2), name='block2_pool')(x)\n","\n","# Block 3\n","# Conv3_1_256\n","x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv1')(x)\n","# Conv3_2_256\n","x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv2')(x)\n","# Conv3_3_256\n","x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv3')(x)\n","# Block3 output for later concatenation\n","block3_conv3_output = x\n","# Batch Normalization3\n","x = BatchNormalization(name='bn3')(x)\n","# MaxPooling3\n","x = MaxPooling2D((2, 2), strides=(2, 2), name='block3_pool')(x)\n","\n","# Block 4\n","# Conv4_1_512\n","x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv1')(x)\n","# Conv4_2_512\n","x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv2')(x)\n","# Conv4_3_512\n","x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv3')(x)\n","# Block4 output for later concatenation\n","block4_conv3_output = x\n","# Batch Normalization4\n","x = BatchNormalization(name='bn4')(x)\n","# MaxPooling4\n","x = MaxPooling2D((2, 2), strides=(2, 2), name='block4_pool')(x)\n","\n","# Block 5\n","# Conv5_1_512\n","x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv1')(x)\n","# Conv5_2_512\n","x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv2')(x)\n","# Conv5_3_512\n","x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv3')(x)\n","# Block5 output for later concatenation\n","block5_conv3_output = x\n","\n","# Downsample the tensors to a consistent shape\n","block1_conv2_downsampled = MaxPooling2D((4, 4))(block1_conv2_output)\n","block2_conv2_downsampled = MaxPooling2D((2, 2))(block2_conv2_output)\n","block3_conv3_downsampled = block3_conv3_output\n","block4_conv3_upsampled = UpSampling2D((2, 2))(block4_conv3_output)\n","block5_conv3_upsampled = UpSampling2D((4, 4))(block5_conv3_output)\n","\n","\n","# Perform depth concatenation on the downsampled tensors\n","x = concatenate([block1_conv2_downsampled, block2_conv2_downsampled, block3_conv3_downsampled, block4_conv3_upsampled, block5_conv3_upsampled], axis=-1)\n","\n","# Batch Normalization5\n","x = BatchNormalization(name='bn5')(x)\n","\n","# Conv6_512\n","x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block6_conv1')(x)\n","\n","# GAPooling6\n","x = GlobalAveragePooling2D(name='gap6')(x)\n","\n","# FC-12\n","output = Dense(4, activation='softmax', name='fc12')(x)\n","\n","# Finally, create the model\n","model = Model(inputs=input_layer, outputs=output)\n","\n","# Print a summary of the model architecture\n","model.summary()"],"metadata":{"id":"h5C5SJoqFKOF","outputId":"ae84c195-65b9-40c6-f74d-afcca04489c8","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model\"\n","__________________________________________________________________________________________________\n"," Layer (type)                   Output Shape         Param #     Connected to                     \n","==================================================================================================\n"," input (InputLayer)             [(None, 224, 224, 3  0           []                               \n","                                )]                                                                \n","                                                                                                  \n"," block1_conv1 (Conv2D)          (None, 224, 224, 64  1792        ['input[0][0]']                  \n","                                )                                                                 \n","                                                                                                  \n"," block1_conv2 (Conv2D)          (None, 224, 224, 64  36928       ['block1_conv1[0][0]']           \n","                                )                                                                 \n","                                                                                                  \n"," bn1 (BatchNormalization)       (None, 224, 224, 64  256         ['block1_conv2[0][0]']           \n","                                )                                                                 \n","                                                                                                  \n"," block1_pool (MaxPooling2D)     (None, 112, 112, 64  0           ['bn1[0][0]']                    \n","                                )                                                                 \n","                                                                                                  \n"," block2_conv1 (Conv2D)          (None, 112, 112, 12  73856       ['block1_pool[0][0]']            \n","                                8)                                                                \n","                                                                                                  \n"," block2_conv2 (Conv2D)          (None, 112, 112, 12  147584      ['block2_conv1[0][0]']           \n","                                8)                                                                \n","                                                                                                  \n"," bn2 (BatchNormalization)       (None, 112, 112, 12  512         ['block2_conv2[0][0]']           \n","                                8)                                                                \n","                                                                                                  \n"," block2_pool (MaxPooling2D)     (None, 56, 56, 128)  0           ['bn2[0][0]']                    \n","                                                                                                  \n"," block3_conv1 (Conv2D)          (None, 56, 56, 256)  295168      ['block2_pool[0][0]']            \n","                                                                                                  \n"," block3_conv2 (Conv2D)          (None, 56, 56, 256)  590080      ['block3_conv1[0][0]']           \n","                                                                                                  \n"," block3_conv3 (Conv2D)          (None, 56, 56, 256)  590080      ['block3_conv2[0][0]']           \n","                                                                                                  \n"," bn3 (BatchNormalization)       (None, 56, 56, 256)  1024        ['block3_conv3[0][0]']           \n","                                                                                                  \n"," block3_pool (MaxPooling2D)     (None, 28, 28, 256)  0           ['bn3[0][0]']                    \n","                                                                                                  \n"," block4_conv1 (Conv2D)          (None, 28, 28, 512)  1180160     ['block3_pool[0][0]']            \n","                                                                                                  \n"," block4_conv2 (Conv2D)          (None, 28, 28, 512)  2359808     ['block4_conv1[0][0]']           \n","                                                                                                  \n"," block4_conv3 (Conv2D)          (None, 28, 28, 512)  2359808     ['block4_conv2[0][0]']           \n","                                                                                                  \n"," bn4 (BatchNormalization)       (None, 28, 28, 512)  2048        ['block4_conv3[0][0]']           \n","                                                                                                  \n"," block4_pool (MaxPooling2D)     (None, 14, 14, 512)  0           ['bn4[0][0]']                    \n","                                                                                                  \n"," block5_conv1 (Conv2D)          (None, 14, 14, 512)  2359808     ['block4_pool[0][0]']            \n","                                                                                                  \n"," block5_conv2 (Conv2D)          (None, 14, 14, 512)  2359808     ['block5_conv1[0][0]']           \n","                                                                                                  \n"," block5_conv3 (Conv2D)          (None, 14, 14, 512)  2359808     ['block5_conv2[0][0]']           \n","                                                                                                  \n"," max_pooling2d (MaxPooling2D)   (None, 56, 56, 64)   0           ['block1_conv2[0][0]']           \n","                                                                                                  \n"," max_pooling2d_1 (MaxPooling2D)  (None, 56, 56, 128)  0          ['block2_conv2[0][0]']           \n","                                                                                                  \n"," up_sampling2d (UpSampling2D)   (None, 56, 56, 512)  0           ['block4_conv3[0][0]']           \n","                                                                                                  \n"," up_sampling2d_1 (UpSampling2D)  (None, 56, 56, 512)  0          ['block5_conv3[0][0]']           \n","                                                                                                  \n"," concatenate (Concatenate)      (None, 56, 56, 1472  0           ['max_pooling2d[0][0]',          \n","                                )                                 'max_pooling2d_1[0][0]',        \n","                                                                  'block3_conv3[0][0]',           \n","                                                                  'up_sampling2d[0][0]',          \n","                                                                  'up_sampling2d_1[0][0]']        \n","                                                                                                  \n"," bn5 (BatchNormalization)       (None, 56, 56, 1472  5888        ['concatenate[0][0]']            \n","                                )                                                                 \n","                                                                                                  \n"," block6_conv1 (Conv2D)          (None, 56, 56, 512)  6783488     ['bn5[0][0]']                    \n","                                                                                                  \n"," gap6 (GlobalAveragePooling2D)  (None, 512)          0           ['block6_conv1[0][0]']           \n","                                                                                                  \n"," fc12 (Dense)                   (None, 4)            2052        ['gap6[0][0]']                   \n","                                                                                                  \n","==================================================================================================\n","Total params: 21,509,956\n","Trainable params: 21,505,092\n","Non-trainable params: 4,864\n","__________________________________________________________________________________________________\n"]}]},{"cell_type":"code","source":["# Configure the optimizer\n","adam = optimizers.Adam()\n","\n","# Compile the model with sparse categorical cross-entropy loss, Adam optimizer, and accuracy metric\n","model.compile(loss='sparse_categorical_crossentropy',\n","              optimizer=adam,\n","              metrics=['accuracy'])\n","\n","# Create an ImageDataGenerator for data augmentation\n","datagen = ImageDataGenerator(\n","    preprocessing_function=preprocess_input,\n","    rotation_range=40,\n","    width_shift_range=0.2,\n","    height_shift_range=0.2,\n","    shear_range=0.2,\n","    zoom_range=0.2,\n","    horizontal_flip=True,\n","    fill_mode='nearest')\n","\n","# Set the paths to your training and testing/validation data\n","train_path = 'G:/Dataset-20230523T171034Z-001/Dataset/train'\n","test_path = 'G:/Dataset-20230523T171034Z-001/Dataset/test'\n","\n","# Create a training data generator\n","train_generator = datagen.flow_from_directory(\n","    train_path,\n","    target_size=IMAGE_SIZE,\n","    batch_size=32,\n","    class_mode='sparse')  # Update class_mode to 'sparse'\n","\n","# Create a testing/validation data generator\n","test_generator = datagen.flow_from_directory(\n","    test_path,\n","    target_size=IMAGE_SIZE,\n","    batch_size=32,\n","    class_mode='sparse')\n","\n","# Modify the activation function for binary classification\n","model.layers[-1].activation = activations.sigmoid\n","\n","# Define a checkpoint to save the best model during training\n","checkpoint = ModelCheckpoint(filepath='mymodel.h5', verbose=2, save_best_only=True)\n","\n","# Create a list of callbacks, including the checkpoint\n","callbacks = [checkpoint]\n","\n","# Record the start time\n","start = datetime.now()\n","\n","# Calculate the number of training and validation steps\n","train_steps = len(train_generator)\n","validation_steps = len(test_generator)\n","\n","# Train the model using the generated data\n","model_history = model.fit(\n","    train_generator,\n","    validation_data=test_generator,\n","    epochs=10,\n","    callbacks=callbacks,\n","    verbose=2)  # Set verbose=1\n","\n","# Calculate the training duration\n","duration = datetime.now() - start\n","print(\"Training completed in time:\", duration)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XCUIIjxyOhlX","outputId":"298de8dd-78ce-41b5-8e67-8233fd203df9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 7058 images belonging to 4 classes.\n","Found 1918 images belonging to 4 classes.\n","Epoch 1/10\n","\n","Epoch 1: val_loss improved from inf to 1.64317, saving model to mymodel.h5\n","221/221 - 3896s - loss: 1.8287 - accuracy: 0.5737 - val_loss: 1.6432 - val_accuracy: 0.4953 - 3896s/epoch - 18s/step\n","Epoch 2/10\n","\n","Epoch 2: val_loss improved from 1.64317 to 1.12584, saving model to mymodel.h5\n","221/221 - 3888s - loss: 0.7276 - accuracy: 0.7328 - val_loss: 1.1258 - val_accuracy: 0.5448 - 3888s/epoch - 18s/step\n","Epoch 3/10\n","\n","Epoch 3: val_loss improved from 1.12584 to 1.00307, saving model to mymodel.h5\n","221/221 - 3883s - loss: 0.5440 - accuracy: 0.7999 - val_loss: 1.0031 - val_accuracy: 0.6762 - 3883s/epoch - 18s/step\n","Epoch 4/10\n","\n","Epoch 4: val_loss did not improve from 1.00307\n","221/221 - 3893s - loss: 0.4352 - accuracy: 0.8405 - val_loss: 1.7383 - val_accuracy: 0.6220 - 3893s/epoch - 18s/step\n","Epoch 5/10\n","\n","Epoch 5: val_loss did not improve from 1.00307\n","221/221 - 3865s - loss: 0.4070 - accuracy: 0.8463 - val_loss: 1.7358 - val_accuracy: 0.6689 - 3865s/epoch - 17s/step\n","Epoch 6/10\n","\n","Epoch 6: val_loss improved from 1.00307 to 0.94961, saving model to mymodel.h5\n","221/221 - 3862s - loss: 0.3447 - accuracy: 0.8779 - val_loss: 0.9496 - val_accuracy: 0.6038 - 3862s/epoch - 17s/step\n","Epoch 7/10\n","\n","Epoch 7: val_loss improved from 0.94961 to 0.81282, saving model to mymodel.h5\n","221/221 - 3888s - loss: 0.3239 - accuracy: 0.8889 - val_loss: 0.8128 - val_accuracy: 0.7914 - 3888s/epoch - 18s/step\n","Epoch 8/10\n","\n","Epoch 8: val_loss improved from 0.81282 to 0.48235, saving model to mymodel.h5\n","221/221 - 3855s - loss: 0.3154 - accuracy: 0.8859 - val_loss: 0.4823 - val_accuracy: 0.8149 - 3855s/epoch - 17s/step\n","Epoch 9/10\n","\n","Epoch 9: val_loss did not improve from 0.48235\n","221/221 - 3862s - loss: 0.2990 - accuracy: 0.8950 - val_loss: 0.6307 - val_accuracy: 0.8217 - 3862s/epoch - 17s/step\n","Epoch 10/10\n","\n","Epoch 10: val_loss did not improve from 0.48235\n","221/221 - 3864s - loss: 0.2790 - accuracy: 0.9027 - val_loss: 0.5308 - val_accuracy: 0.8045 - 3864s/epoch - 17s/step\n","Training completed in time: 10:45:56.713682\n"]}]},{"cell_type":"code","source":["# Plot training & validation loss values\n","plt.plot(model_history.history['accuracy'])\n","plt.plot(model_history.history['val_accuracy'])\n","plt.title('Improved CNN Model accuracy values')\n","plt.ylabel('Accuracy')\n","plt.xlabel('Epoch')\n","plt.legend(['Train', 'Test'], loc='upper left')\n","plt.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":217},"id":"JUPwAw-dvXd-","outputId":"d1a9b651-999d-46d1-f72b-46d104d6282c"},"execution_count":null,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[1;32mIn[3], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Plot training & validation loss values\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(\u001b[43mmodel_history\u001b[49m\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m      3\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(model_history\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m      4\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mImproved CNN Model accuracy values\u001b[39m\u001b[38;5;124m'\u001b[39m)\n","\u001b[1;31mNameError\u001b[0m: name 'model_history' is not defined"]}]}]}